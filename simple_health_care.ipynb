{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Simple Health Care"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Health Care is a fictitious startup that aims to reduce the number of tests required for the diagnosis of a specific type of cancer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Project developed as a study to deal with high-dimensional data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports and preprocess the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "uri = \"data/exams.csv\"\r\n",
    "data = pd.read_csv(uri)\r\n",
    "\r\n",
    "data = data.rename(columns = {\"diagnostico\": \"diagnostic\"})\r\n",
    "data.columns = data.columns.str.replace('exame', 'exam')\r\n",
    "\r\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id diagnostic  exam_1  exam_2  exam_3  exam_4  exam_5   exam_6  \\\n",
       "0    842302          M   17.99   10.38  122.80  103.78  1001.0  0.11840   \n",
       "1    842517          M   20.57   17.77  132.90  103.78  1326.0  0.08474   \n",
       "2  84300903          M   19.69   21.25  130.00  103.78  1203.0  0.10960   \n",
       "3  84348301          M   11.42   20.38   77.58  103.78   386.1  0.14250   \n",
       "4  84358402          M   20.29   14.34  135.10  103.78  1297.0  0.10030   \n",
       "\n",
       "    exam_7  exam_8  ...  exam_24  exam_25  exam_26  exam_27  exam_28  exam_29  \\\n",
       "0  0.27760  0.3001  ...   184.60   2019.0   0.1622   0.6656   0.7119    0.786   \n",
       "1  0.07864  0.0869  ...   158.80   1956.0   0.1238   0.1866   0.2416    0.786   \n",
       "2  0.15990  0.1974  ...   152.50   1709.0   0.1444   0.4245   0.4504    0.786   \n",
       "3  0.28390  0.2414  ...    98.87    567.7   0.2098   0.8663   0.6869    0.786   \n",
       "4  0.13280  0.1980  ...   152.20   1575.0   0.1374   0.2050   0.4000    0.786   \n",
       "\n",
       "   exam_30  exam_31  exam_32   exam_33  \n",
       "0   0.2654   0.4601  0.11890       NaN  \n",
       "1   0.1860   0.2750  0.08902       NaN  \n",
       "2   0.2430   0.3613  0.08758       NaN  \n",
       "3   0.2575   0.6638  0.17300       NaN  \n",
       "4   0.1625   0.2364  0.07678  0.854454  \n",
       "\n",
       "[5 rows x 35 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>exam_4</th>\n",
       "      <th>exam_5</th>\n",
       "      <th>exam_6</th>\n",
       "      <th>exam_7</th>\n",
       "      <th>exam_8</th>\n",
       "      <th>...</th>\n",
       "      <th>exam_24</th>\n",
       "      <th>exam_25</th>\n",
       "      <th>exam_26</th>\n",
       "      <th>exam_27</th>\n",
       "      <th>exam_28</th>\n",
       "      <th>exam_29</th>\n",
       "      <th>exam_30</th>\n",
       "      <th>exam_31</th>\n",
       "      <th>exam_32</th>\n",
       "      <th>exam_33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>...</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>...</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>103.78</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.854454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove unnecessary columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_v1 = data.drop(columns=\"exam_33\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split the data into train and test\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from numpy import random\r\n",
    "\r\n",
    "SEED = 123\r\n",
    "random.seed(SEED)\r\n",
    "\r\n",
    "x = data_v1.drop(columns=['id', 'diagnostic'])\r\n",
    "y = data_v1.diagnostic\r\n",
    "\r\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size = 0.3)\r\n",
    "\r\n",
    "clf = RandomForestClassifier(n_estimators = 100)\r\n",
    "clf.fit(train_x, train_y)\r\n",
    "acc = clf.score(test_x, test_y)\r\n",
    "acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.dummy import DummyClassifier\r\n",
    "\r\n",
    "SEED = 123\r\n",
    "random.seed(SEED)\r\n",
    "\r\n",
    "dummy = DummyClassifier(strategy = \"most_frequent\")\r\n",
    "dummy.fit(train_x, train_y)\r\n",
    "acc = dummy.score(test_x, test_y)\r\n",
    "acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_violin_graph(X, start, end):\r\n",
    "    import seaborn as sns\r\n",
    "    import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "    data_plot = pd.concat([y, X.iloc[:, start:end]], axis = 1)\r\n",
    "    data_plot = pd.melt(data_plot, id_vars = \"diagnostic\", var_name = \"exams\", value_name = \"values\")\r\n",
    "\r\n",
    "    plt.figure(figsize = (10, 10))\r\n",
    "    plt.xticks(rotation = 90)\r\n",
    "    sns.violinplot(x = \"exams\", y = \"values\", hue = \"diagnostic\", data = data_plot, split = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "scaler = StandardScaler()\r\n",
    "scaler.fit(x)\r\n",
    "x_v2 = scaler.transform(x)\r\n",
    "x_v2 = pd.DataFrame(data = x_v2, columns = x.keys())\r\n",
    "\r\n",
    "plot_violin_graph(x_v2, 0, 10)\r\n",
    "plot_violin_graph(x_v2, 11, 20)\r\n",
    "plot_violin_graph(x_v2, 21, 30)\r\n",
    "plot_violin_graph(x_v2, 30, 41)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove constant value columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_v3 = x_v2.drop(columns = [\"exam_4\", \"exam_29\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def classify(X):\r\n",
    "    from sklearn.model_selection import train_test_split\r\n",
    "    from sklearn.ensemble import RandomForestClassifier\r\n",
    "    from numpy import random\r\n",
    "\r\n",
    "    SEED = 123\r\n",
    "    random.seed(SEED)\r\n",
    "\r\n",
    "    x = data_v1.drop(columns=['id', 'diagnostic'])\r\n",
    "    y = data_v1.diagnostic\r\n",
    "\r\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3)\r\n",
    "\r\n",
    "    clf = RandomForestClassifier(n_estimators = 100)\r\n",
    "    clf.fit(train_x, train_y)\r\n",
    "    acc = clf.score(test_x, test_y) * 100\r\n",
    "    print(f'{acc:.2f}%')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classify(x_v3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "x_correlated = x_v3.corr()\r\n",
    "plt.figure(figsize = (17, 15))\r\n",
    "sns.heatmap(x_correlated, annot = True, fmt = \".1f\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_correlated_v1 = x_correlated[x_correlated > 0.99]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_correlated_v2 = x_correlated_v1.sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "correlated_vars = x_correlated_v2[x_correlated_v2 > 1]\r\n",
    "correlated_vars"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_v4 = x_v3.drop(columns = correlated_vars.keys())\r\n",
    "x_v4.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classify(x_v4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_v5 = x_v3.drop(columns = [\"exam_3\", \"exam_24\"])\r\n",
    "x_v5.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classify(x_v5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\r\n",
    "\r\n",
    "kbest_features = SelectKBest(chi2, k = 5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_v6 = x.drop(columns = [\"exam_3\", \"exam_4\", \"exam_24\", \"exam_29\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "SEED = 123\r\n",
    "random.seed(SEED)\r\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_v6, y, test_size = 0.3)\r\n",
    "\r\n",
    "kbest_features.fit(train_x, train_y)\r\n",
    "train_x_kbest = kbest_features.transform(train_x)\r\n",
    "test_x_kbest = kbest_features.transform(test_x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_x_kbest.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf = RandomForestClassifier(n_estimators = 100, random_state = SEED)\r\n",
    "clf.fit(train_x_kbest, train_y)\r\n",
    "acc = clf.score(test_x_kbest, test_y) * 100\r\n",
    "print(f'{acc:.2f}%')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix\r\n",
    "\r\n",
    "conf_matrix = confusion_matrix(test_y, clf.predict(test_x_kbest))\r\n",
    "conf_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize = (10, 8))\r\n",
    "sns.set(font_scale = 1.25)\r\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \"d\").set(xlabel = \"Predict\", ylabel = \"Real\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_selection import RFE\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from numpy import random\r\n",
    "\r\n",
    "SEED = 123\r\n",
    "random.seed(SEED)\r\n",
    "\r\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_v6, y, test_size = 0.3)\r\n",
    "\r\n",
    "clf = RandomForestClassifier(n_estimators = 100, random_state = SEED)\r\n",
    "clf.fit(train_x, train_y)\r\n",
    "\r\n",
    "rfe = RFE(estimator = clf, n_features_to_select = 5, step = 1)\r\n",
    "rfe.fit(train_x, train_y)\r\n",
    "train_rfe_x = rfe.transform(train_x)\r\n",
    "test_rfe_x = rfe.transform(test_x)\r\n",
    "clf.fit(train_rfe_x, train_y)\r\n",
    "\r\n",
    "conf_matrix = confusion_matrix(test_y, clf.predict(test_rfe_x))\r\n",
    "\r\n",
    "score = clf.score(test_rfe_x, test_y) * 100\r\n",
    "\r\n",
    "plt.figure(figsize = (10, 8))\r\n",
    "sns.set(font_scale = 1.25)\r\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \"d\").set(xlabel = \"Predict\", ylabel = \"Real\")\r\n",
    "\r\n",
    "print(f'{score:.2f}%')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_selection import RFECV\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from numpy import random\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "uri = \"data/exams.csv\"\r\n",
    "data = pd.read_csv(uri)\r\n",
    "\r\n",
    "data = data.rename(columns = {\"diagnostico\": \"diagnostic\"})\r\n",
    "data.columns = data.columns.str.replace('exame', 'exam')\r\n",
    "\r\n",
    "data_v1 = data.drop(columns=\"exam_33\")\r\n",
    "\r\n",
    "x = data_v1.drop(columns=['id', 'diagnostic'])\r\n",
    "y = data_v1.diagnostic\r\n",
    "\r\n",
    "x_v6 = x.drop(columns = [\"exam_3\", \"exam_4\", \"exam_24\", \"exam_29\"])\r\n",
    "\r\n",
    "SEED = 123\r\n",
    "random.seed(SEED)\r\n",
    "\r\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_v6, y, test_size = 0.3)\r\n",
    "\r\n",
    "clf = RandomForestClassifier(n_estimators = 100, random_state = SEED)\r\n",
    "clf.fit(train_x, train_y)\r\n",
    "rfecv = RFECV(estimator = clf, cv = 5, step = 1, scoring = \"accuracy\")\r\n",
    "rfecv.fit(train_x, train_y)\r\n",
    "train_rfecv_x= rfecv.transform(train_x)\r\n",
    "test_rfecv_x = rfecv.transform(test_x)\r\n",
    "clf.fit(train_rfecv_x, train_y)\r\n",
    "\r\n",
    "conf_matrix = confusion_matrix(test_y, clf.predict(test_rfecv_x))\r\n",
    "\r\n",
    "score = clf.score(test_rfecv_x, test_y) * 100\r\n",
    "\r\n",
    "plt.figure(figsize = (10, 8))\r\n",
    "sns.set(font_scale = 1.25)\r\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \"d\").set(xlabel = \"Predict\", ylabel = \"Real\")\r\n",
    "\r\n",
    "print(f'{score:.2f}%')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_x.columns[rfecv.support_]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(rfecv.grid_scores_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "plt.figure(figsize = (14, 8))\r\n",
    "plt.xlabel(\"Total exams\")\r\n",
    "plt.ylabel(\"Accuracy\")\r\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_selection import RFE\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from numpy import random\r\n",
    "\r\n",
    "SEED = 123\r\n",
    "random.seed(SEED)\r\n",
    "\r\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_v6, y, test_size = 0.3)\r\n",
    "\r\n",
    "clf = RandomForestClassifier(n_estimators = 100, random_state = SEED)\r\n",
    "clf.fit(train_x, train_y)\r\n",
    "\r\n",
    "rfe = RFE(estimator = clf, n_features_to_select = 2, step = 1)\r\n",
    "rfe.fit(train_x, train_y)\r\n",
    "train_rfe_x = rfe.transform(train_x)\r\n",
    "test_rfe_x = rfe.transform(test_x)\r\n",
    "clf.fit(train_rfe_x, train_y)\r\n",
    "\r\n",
    "conf_matrix = confusion_matrix(test_y, clf.predict(test_rfe_x))\r\n",
    "\r\n",
    "score = clf.score(test_rfe_x, test_y) * 100\r\n",
    "\r\n",
    "plt.figure(figsize = (10, 8))\r\n",
    "sns.set(font_scale = 1.25)\r\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \"d\").set(xlabel = \"Predict\", ylabel = \"Real\")\r\n",
    "\r\n",
    "print(f'{score:.2f}%')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_v7 = rfe.transform(x_v6)\r\n",
    "x_v7.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sns\r\n",
    "\r\n",
    "plt.figure(figsize = (14, 8))\r\n",
    "sns.scatterplot(x = x_v7[:, 0], y = x_v7[:, 1], hue = y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.decomposition import PCA\r\n",
    "\r\n",
    "pca = PCA(n_components = 2)\r\n",
    "x_v8 = pca.fit_transform(x_v5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.scatterplot(x = x_v8[:, 0], y = x_v8[:, 1], hue = y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.manifold import TSNE\r\n",
    "\r\n",
    "tsne = TSNE(n_components = 2)\r\n",
    "x_v9 = tsne.fit_transform(x_v5)\r\n",
    "sns.scatterplot(x = x_v9[:, 0], y = x_v9[:, 1], hue = y)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}